{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import string\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "import lightfm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymorphy2\n",
    "import scipy.sparse\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(s):\n",
    "    return \" \".join(\n",
    "        [morph.normal_forms(word)[0] for word in s.translate(table).lower().split()]\n",
    "    )\n",
    "\n",
    "\n",
    "def process_item_line(line):\n",
    "    item = json.loads(line)\n",
    "    if isinstance(item[\"image\"], float):\n",
    "        item[\"image\"] = np.full((96,),0)\n",
    "    else:\n",
    "        item[\"image\"] = np.array(item[\"image\"])\n",
    "    item[\"content\"] = clean_text(item[\"content\"])\n",
    "    item[\"title\"] = clean_text(item[\"title\"])\n",
    "    return item\n",
    "\n",
    "chars_to_replace=string.punctuation + \"«»\\n—–\"\n",
    "table = str.maketrans(chars_to_replace, \" \"*len(chars_to_replace))\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "items_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../input/items.json/items.json\") as inf:\n",
    "    with Pool(cpu_count()) as p:\n",
    "        items_list = list(p.imap(process_item_line, inf))\n",
    "\n",
    "items = pd.DataFrame(items_list).set_index(\"itemId\")\n",
    "num_users = 42977\n",
    "num_items = len(items)\n",
    "data = []\n",
    "row = []\n",
    "col = []\n",
    "with open(\"../input/train.json/train.json\") as inf:\n",
    "    for i, line in enumerate(inf):\n",
    "        j = json.loads(line)\n",
    "        for item, rating in j[\"trainRatings\"].items():\n",
    "            data.append((-1) ** (int(rating) + 1))\n",
    "            row.append(i)\n",
    "            col.append(int(item))\n",
    "train_int = scipy.sparse.coo_matrix((data, (row, col)))\n",
    "print(\"created train interactions\")\n",
    "del data, row, col\n",
    "vect_content = TfidfVectorizer(min_df=90, max_df=0.01, lowercase=False)\n",
    "tfidf_content = vect_content.fit_transform(items.content)\n",
    "print(\"transformed content\")\n",
    "vect_title = TfidfVectorizer(min_df=90, max_df=0.01, lowercase=False)\n",
    "tfidf_title = vect_title.fit_transform(items.title)\n",
    "print(\"transformed title\")\n",
    "identity_items = scipy.sparse.eye(num_items)\n",
    "item_features = scipy.sparse.hstack(\n",
    "    [identity_items, tfidf_content, tfidf_title], format=\"csr\"\n",
    ")\n",
    "model = lightfm.LightFM(no_components=128, loss=\"logistic\", random_state=0)\n",
    "print(\"start training\")\n",
    "model.fit(train_int, epochs=7, num_threads=cpu_count(), item_features=item_features)\n",
    "print(\"end training\")\n",
    "sample = pd.read_csv(\"../input/random_benchmark.csv\")\n",
    "sample[\"pred\"] = model.predict(\n",
    "    sample.userId.values,\n",
    "    sample.itemId.values,\n",
    "    item_features=item_features,\n",
    "    num_threads=cpu_count(),\n",
    ")\n",
    "sample.sort_values([\"userId\", \"pred\"], ascending=[True, False], inplace=True)\n",
    "sample.drop(columns=[\"pred\"], inplace=True)\n",
    "sample.to_csv(\"lightfm_tfidf.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
